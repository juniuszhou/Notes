discuss.txt

   宜信那边引入presto的背景是，有一些业务场景，业务人员需要即席查询hive表中的结构化数据，辅助平时的分析。基于mapreduce 的hive 查询引擎无法满足查询速度，
同时当时存放hive表的hadoop 集群没有部署spark，单纯为了即席查询上spark 成本太高（主要是当时团队懂spark的人不多）, 所以，对比hive,presto和impala后，选择了presto. 

  1） 存放hive表的hadoop集群有20个datanode,单台内存64G，给每台datanode都部署了presto worker,单台最大查询内存设置了20G。hive表的数量有500多张。这些表都是按日期分区存放，数据格式是Parquet文件。
单分区最大的数据量有上亿条数据，80%的单分区的数据量在几百万条。已经积累了4年的数据。
查询场景涉及 join, count ,distinct ,group by 等常用sql 及一些常用的窗口函数(sum,avg,rank,row_number等)。
查询性能方面：在并发量小的(<10的QPS)情况下，基本可以做到在1分钟内查到结果。并发量达到几十的情况下，会出现排队现象。主要瓶颈是内存。
因为是给上万名理财门店的业务人员使用，平时每天查询的sql数量在10万多个。主要集中在白天工作时间。并发qps 30-50的情况，比较多。
这种情况下，占用大量内存的查询就会排队，等待2分钟以上取到结果，比较常见。
  

  2） 宜信遇到的presto的一些坑：1. 纯内存，没有容错，一个task失败就整个query fail。失败重试，这一点不如spark 
                                2. 参数方面，需要注意调整内存相关，线程数等参数，否则容易OOM
  
  3) 和yarn 的集成方面：宜信部署的版本，没有用yarn进行调度。所以，sql查询之间没法做优先级的设置和资源抢占,资源预留和隔离。sql执行顺序是先到先执行。
  我看了一下目前的presto 官方文档，没有和yarn集成的说明。
  网上搜到  https://github.com/prestodb/presto-yarn 这个扩展项目，里面有和yarn集成的说明，但是需要hadoop 集群： A cluster with HDP 2.2+ or CDH5.4+ installed。
  不知道和我们目前用的apache 版本兼容性如何。该项目活跃度不太高。更新还停留在几个月前。
  
  4） presto监控等功能，比较弱。
  
  5） coodinator是单点
  
  6） 宜信目前的spark集群，现在也已经投入使用。基于presto上面提到的这些问题，他们也正开始尝试用spark sql 来做即席查询。
  我们这边已经对spark积累了一些经验，结合Alluxio和yarn，做好数据缓存，资源隔离，资源抢占，执行优先级等工作，spark sql来做实时查询也是一个可行的方案。




1. kylin 预计算。用户指定dimensions和要计算的metric，kylin通过MR将结果保存在HBase中，后续读取直接读HBase。适合那种业务清楚的知道自己要分析什么的场景。查询模式比较固定，只不过所查看的时间不同的场景。注意的点是要避免维度灾难。2. presto java8写的，代码质量非常高。设计：纯内存，没有容错，一个task失败就整个query fail。需要注意调整内存相关，线程数等参数，容易OOM。benchmark还行。支持标准SQL3. spark sql  个人觉得支持查询Hive的数据，支持HQL非常重要，因为很多公司以前的数据都是放在Hive上的。我们测试了spark sql 2.0.1，对于鄙司这种分区数很多，每个分区很多parquet文件的情形来说，几乎不可用，原因在于 [SPARK-16980] Load only catalog table partition metadata required to answer a query 转而测试spark sql 2.1.0， 结果还是比较满意的。不过容错性还有待检验，benchmark过程中如果个别task失败，job 有时候会hang住，待分析。



