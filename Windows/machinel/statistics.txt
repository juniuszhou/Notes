每当我们讨论概率时，我们其实都是在对概率密度进行积分。在贝叶斯分析中，我们所用到的很多概率密度都不是能解析表达的：对它们积分你需要付出很大的代价，如果它们真的可积。所以，我们用一种代替的方法，就是大量的仿真这个随机变量，然后从我们仿真出的随机数里得到概率。如果我们想要知道X小于10的概率，我们就计算仿真出的随机数里小于10的比例，用它作为我们的估算结果。这就是“蒙特卡洛”部分，它是一种基于随机数的概率估计方法。当仿真出的随机数足够多的时候，估计的结果就非常好，但是它本质上仍然是随机的。
那又为什么用“马尔科夫”呢？因为在特定的技术条件下，你可以生成一个无记忆的过程（例如，一个马尔科夫过程），这个过程和你想要仿真的随机变量有一样的分布。你可以迭代任意数量的不同的仿真过程，这些仿真过程可以生成相关的随机数（只基于这些数的当前值），并且这个过程保证了一旦你生成足够多的结果，你将能得到一组数，它们看起来就好像你用某种方法成功地从你想要知道的复杂分布中获得了独立的样本一样。
例如，如果我想估计一个标准正态分布的随机变量小于0.5的概率，我可以从标准正态分布中生成10000个独立的样本，然后数出其中小于0.5的样本的数量；假设，我得到6905个样本小于0.5，那么我对P(Z<0.5)的估计就是0.6905，这个估计和真实值相去不远。这就是个蒙特卡洛估计。
现在想像我没办法生成独立的标准正态分布的随机变量，于是我从0开始，每一步加一些-0.5到0.5之间均匀分布的随机数到我的当前值，然后根据一种特殊的检验方法来决定我是不是接受这个新值，如果我不接受，那我就拒绝这个值保留我的旧值。因为我只考虑新值和当前值，所以这是个马尔科夫链。如果我正确地建立了决定是否保留新值的检验方法（可以是随机游走Metropolis-Hastings方法，细节比较复杂），于是尽管我没生成哪怕一个正态随机变量，如果我仿真这个过程足够长时间，我从这个过程得到的数列就将分布得像用某种方法生成的正态随机变量的大量样本一样。这就是对一个标准正态分布随机变量的马尔科夫蒙特卡洛仿真。如果我用这种方法去估计概率，这就是一个马尔科夫蒙特卡洛估计。


一、结构风险
结构风险=经验风险+置信风险
经验风险=分类器的训练误差
置信风险=分类器的测试误差
其中置信风险由样本数量N与分类函数的VC维h决定。样本数量越多模型越接近真实分布，置信风险越小；
VC维越大，模型越复杂推广性差，置信风险越大。结构风险公式如下：
二、VC维
定义：若h个样本能被分类函数按所有可能的2h种形式分开，则称分类函数能把h个样本打散。分类函数的VC为就是它能打散的最大样本数h。若分类边界为线性，则h=D+1，D为特征维数。
[例]2维平面内只能找到3个点被直线打散分成两堆。设A、B、C表示三个点，+1，-1表示堆的类别。
当h=3时，有8种打散方式：

当h=4时，只有14种打散方式（应该有24=16种）
  
因此VC维等于3。



Optimisation is the root of all evil in statistics. Any time you make choices about your model1 by optimising some suitable criterion evaluated on a finite sample of data you run the risk of over-fitting the criterion, i.e. reducing the statistic beyond the point where improvements in generalisation performance are obtained and the reduction is instead gained by exploiting the peculiarities of the sample of data, e.g. noise). The reason the Bayesian method works better is that you don't optimise anything, but instead marginalise (integrate) over all possible choices. The problem then lies in the choice of prior beliefs regarding the model, so one problem has gone away, but another one appears in its place. 


 The advantage of imposing priors for instance through regularisation is that the parameters are either shrunk to zero or some other predefined value (you can even add parameters to "tie" the coefficients together if you like), and thus you are implicitly constraining the parameters and reducing the "freedom" of your model to overfit. For example, using the lasso (ie. l1 regularisation or equivalently a Laplace prior) and tuning the corresponding parameter (using 10x cross validation for example) will automatically get rid of the surplus parameters. The Bayesian interpretation is similar : by imposing priors, you are constraining your parameters to some more probable value, inferred from the overall data. 



随机场（Random field）是指有一个样本空间，空间中的每个随机变量所形成的序列就是
随机场。
位置 site    一个样本
相空间 phase space  每个样本的可能的取值

CRF 是一个在处理自然语言中使用非常广泛的算法，也有人把它扩展到二维的CRF，可以
用做二维的图像处理。



Markov 性质：一般说的是过去和将来没有关系，一个状态只依赖于前一个状态。
Markov random filed，就是只有site 位置相邻的相空间 的取值有联系。


 我们不妨拿种地来打个比方。“位置”好比是一亩亩农田； “相空间”好比是种的各种庄稼。我们可以给不同的地种上不同的庄稼，这就好比给随机场的每个“位置”，赋予相空间里不同的值。所以，俗气点说，随机场就是在哪块地里种什么庄稼的事情。 


马尔科夫链
 用一个通俗的比喻来形容，一只被切除了大脑的白鼠在若干个洞穴间的蹿动就构成一个马尔科夫链。 



 条件随机场(Conditional random fields)，是一种判别式图模型，因为其强大的表达能力和出色的性能，得到了广泛的应用。从最通用角度来看，CRF本质上是给定了观察值集合 (observations)的马尔可夫随机场。

 条件随机场则使用一种概率图模型，具有表达长距离依赖性和交叠性特征的能力 

 


上节我们得到，一个最大熵模型可以有效地把各种信息综合在一起（无偏见地对待不确定性），而且具有指数函数的形式，下面模型的训练就要确定这个指数 函数的各个参数。最原始的最大熵模型的训练方法是一种称为通用迭代算法 GIS(generalized iterative scaling) 的迭代算法，由 Darroch 和 Ratcliff 在七十年代提出，大致可以概括为以下几个步骤：
1. 假定第零次迭代的初始模型为等概率的均匀分布。
2. 用第 N 次迭代的模型来估算每种信息特征在训练数据中的分布，如果超过了实际的，就把相应的模型参数变小；否则，将它们便大。
3. 重复步骤 2 直到收敛。
Darroch 和 Ratcliff没有能对这种算法的物理含义进行很好地解释，后来是由Csiszar解释清楚的，因此，人们在谈到这个算法时，总是同时引用 Darroch 和Ratcliff 以及希萨的两篇论文。GIS 算法每次迭代的时间都很长，需要迭代很多次才能收敛，而且不太稳定，即使在 64 位计算机上都会出现溢出。因此，在实际应用中很少有人真正使用，大家只是通过它来了解最大熵模型的算法。
八十年代，Della Pietra在IBM对GIS算法进行了两方面的改进，提出了改进迭代算法IIS（improved iterative scaling）。这使得最大熵模型的训练时间缩短了一到两个数量级。这样最大熵模型才有可能变得实用。即使如此，在当时也只有 IBM 有条件是用最大熵模型。
由于最大熵模型在数学上十分完美，对科学家们有很大的诱惑力，因此不少研究者试图把自己的问题用一个类似最大熵的近似模型去套。谁知这一近似，最大 熵模型就变得不完美了，结果可想而知，比打补丁的凑合的方法也好不了多少。于是，不少热心人又放弃了这种方法。第一个在实际信息处理应用中验证了最大熵模 型的优势的，是原IBM现微软的研究员Adwait Ratnaparkhi。Ratnaparkhi的聪明之处在于他没有对最大熵模型进行近似，而是找到了几个最适合用最大熵模型、而计算量相对不太大的自然语言处理问题，比如词性标注和句法分析。拉纳帕提成功地将上下文信息、词性（名词、动词和形容词等）、句子成分（主谓宾）通过最大熵模型结合起来，做出了当时世界上最好的词性标识系统和句法分析器。





最大entropy 模型
比如有一组观察到的变量的序列，最大条件entropy就是在以这个序列为条件的情况下，去最大化
y可以使x的某个属性，输出。比如NLP，序列是一些文字，而y可以是对文字的标注，比如哪个应该
是主语，谓语，动词等。


Naive Bayes 模型
是一个有向图，它的分类基于联合概率的比较，找到最有可能的作为分类，是generative模型。
联合概率往往比较难得到，于是我们要找到feature之间的dependence的关系。
这样就可以画出这个DAG图，用这个图中的依赖方向来求得概率。


一介markov模型
它只有状态的转换概率matrix和初始状态概率。用来可以预测未来会发生某种序列的概率。
或者是最有可能的概率。

Hidden markov模型
是状态的转换我们是看不到的，我门只有observed数据，而数据是dependent在状态上的。
这个模型中，我们有转换概率matrix和初始观察取值，还有观察值在每个状态的概率。
3个classic 问题
1. 评价，莫个序列的概率
2. 解码， 最有可能的序列
3. 参数学习


MEM max entropy
1. 引入了条件entropy，就是在有观察值序列的条件下，output的条件概率
2. 特征函数

它就是要最大化，在有了这个序列的情况下，最大化它的概率。

它的图模型是，在二个点之间加入了特征函数。




MEMM
HMM：状态集合Y，观察值集合X，  两个状态转移概率：从yi-1到yi的条件概率分布P(yi | yi-1)，状态yi的输出观察值概率P (xi| yi)，初始概率P0(y).

MEMM：用一个P(yi | yi-1 ,xi)分布来替代HMM中的两个条件概率分布，它表示从先前状态，在观察值下得到当前状态的概率，即根据前一状态和当前观察预测当前状态。每个这样的分布函数都是一个服从最大熵的指数模型。



CRF

最简单的一介链式CRF .



机器学习(Machine Learning, ML)的目的是根据给定的训练样本求对某系统输入输出之间依赖关系的估计，使它（这种关系）能够对未知输出做出尽可能准确地预测。机器学习至今没有一个精 确的公认的定义。作为人工智能(Artificial Intelligence, AI)的一个重要研究领域，ML的研究工作主要围绕学习机理、学习方法和面向任务这三个基本方面进行研究。模式识别、函数逼近和概率密度估计是三类基本的ML问题。 
从数学的角度来考虑，机器学习问题就是已知n个独立同分布的观测样本，在同一组预测函数中求一个最优的函数对依赖关系进行估计，使期望风险R[f]最小。损失函数是评价预测准确程度的一种度量，它与预测函数f(x)密切相关。而f(x)的期望风险依赖于概率分布和损失函数，前者是客观存在的，后者是根据具体问题选定的，带有（主观的）人为的或偏好色彩。期望风险的大小直观上可以理解为，当我们用f(x)进行预测时，“平均”的损失程度，或“平均”犯错误的程度。 
但是，只有样本却无法计算期望风险，因此，传统的学习方法用样本定义经验风险Remp[f]作为对期望风险的估计，并设计学习算法使之最小化。即所谓的经验风险最小化(Empirical Risk Minimization, ERM)归纳原则。经验风险是用损失函数来计算的。对 于模式识别问题的损失函数来说，经验风险就是训练样本错误率；对于函数逼近问题的损失函数来说，就是平方训练误差；而对于概率密度估计问题的损失函数来 说，ERM准则就等价于最大似然法。事实上，用ERM准则代替期望风险最小化并没有经过充分的理论论证，只是直观上合理的想当然做法。也就是说，经验风险最小不一定意味着期望风险最小。其实，只有样本数目趋近于无穷大时，经验风险才有可能趋近于期望风险。但是很多问题中样本数目离无穷大很远，那么在有限样本下ERM准则就不一定能使真实风险较小啦。ERM准则不成功的一个例子就是神经网络的过学习问题（某些情况下，训练误差过小反而导致推广能力下降，或者说是训练误差过小导致了预测错误率的增加，即真实风险的增加）。 
统计学习理论(Statistical Learning Theory, SLT)和支持向量机(Support Vector Machine, SVM)建立了一套较好的有限训练样本下机器学习的理论框架和通用方法，既有严格的理论基础，又能较好地解决小样本、非线性、高维数和局部极小点等实际问 题，其核心思想就是学习机器（又叫预测函数，或学习函数，或学习模型）F要与有限的训练样本相适应。在学习算法中需要选择恰当的F，这里的关键因素是F的大小，或者F的丰富程度，或者说F的“表达能力”，VC维(Vapnik-Chervonenkis Dimension)就是对这种“表达能力”的一种描述。
 
VC维的定义如下：对于一个指示函数集，如果存在h个样本能够被函数集中的函数按所有可能的2的h次幂种形式分开，则称函数集能够把h个样本都打散，h的最大值就是函数集的VC维。VC维是SLT中的一个重要概念，它是函数集学习性能的重要指标。目前尚没有通用的关于任意函数集VC维计算的理论，只知道一些特殊的函数集的VC维。

比如，在n维空间中线性分类器和线性实函数的VC维是 n+1，而 f(x,a) = sin(ax) 的VC维则为无穷大。对于给定的学习函数集，如何（用理论或实验的方法）计算其VC维是当前统计学习理论中有待研究的一个问题。
 
由上文可知，在有限样本情况下，仅仅用ERM来近似期望风险是行不通的。统计学习理论给出了期望风险 R[f] 与经验风险 Remp[f] 之间关系：R[f] <= ( Remp[f] + e )。其中 e = g(h/n) 为置信区间，e 是VC维 h 的增函数，也是样本数n的减函数。右端称为结构风险，它是期望风险 R[f] 的一个上界。经验风险的最小依赖较大的 F （样本数较多的函数集）中某个 f 的选择，但是 F 较大，则VC维较大，就导致置信区间 e 变大，所以要想使期望风险 R[f] 最小，必须选择合适的 h 和 n 来使不等式右边的结构风险最小，这就是结构风险最小化(Structural Risk Minimization, SRM)归纳原则。实现SRM的思路之一就是设计函数集的某种结构使每个子集中都能取得最小的经验风险（如使训练误差为0），然后只需选择适当的子集使置信范围最小，则这个子集中使经验风险最小的函数就是最优函数。SVM方法实际上就是这种思想的具体实现。
 
SVM是一种基于统计的学习方法，它是对SRM的近似。概括地说，SVM就是首先通过用内积函数定义的非线性变换将输入空间变换到一个高维空间，然后再在这个空间中求（广义）最优分类面的分类方法。


结构化风险 = 经验风险 + 置信风险
经验风险 =  分类器在给定样本上的误差 
置信风险 = 分类器在未知文本上分类的结果的误差
置信风险因素：

	* 样本数量，给定的样本数量越大，学习结果越有可能正确，此时置信风险越小；
	* 分类函数的VC维，显然VC维越大，推广能力越差，置信风险会变大。

提高样本数量，降低VC维，降低置信风险。
以前机器学习的目标是降低经验风险，要降低经验风险，就要提高分类函数的复杂度，导致VC维很高，VC维高，置信风险就高，所以，结构风险也高。---- 这是SVM比其他机器学习具有优势的地方。


结构风险最小化等价于正则化（regularization），即在经验风险的后面加上与模型复杂度相符的正则化项（regularizer）
或惩罚项（penalty term）





norms 
若为维向量，那么定义p-范数为
当时是比较常用的范数。
其中1-范数是向量个分量绝对值之和：

2-范数（Euclid范数）就是通常所说的向量的长度，在正交变换的情况下是不变的范数：


-范数通常所说的最大值范数，指的是向量各个分量绝对值的最大值：[2]

0-范数是向量中非零分量的个数：

其中

是指标函数，当输入为真时等于1，否则等于0。




 卷积、旋积或摺积(英语：Convolution)是通过两个函数f 和g 生成第三个函数的一种数学算子，表征函数f 与经过翻转和平移的g 的重叠部分的累积。 

简单介绍
卷积的定义
卷积是分析数学中一种重要的运算。设:f(x),g(x)是R1上的两个可积函数，作积分（如右图）：
可以证明，关于几乎所有的实数x，上述积分是存在的。这样，随着x的不同取值，这个积分就定义了一个新函数h(x)，称为函数f与g的卷积，记为h(x)=(f*g)(x)。容易验证，(f * g)(x) = (g * f)(x)，并且(f * g)(x)仍为可积函数。这就是说，把卷积代替乘法，L1（R1）1空间是一个代数，甚至是巴拿赫代数。
卷积与傅里叶变换有着密切的关系。利用一点性质，即两函数的傅里叶变换的乘积等于它们卷积后的傅里叶变换，能使傅里叶分析中许多问题的处理得到简化。
由卷积得到的函数f*g一般要比f和g都光滑。特别当g为具有紧致集的光滑函数，f为局部可积时，它们的卷积f * g也是光滑函数。利用这一性质，对于任意的可积函数f，都可以简单地构造出一列逼近于f的光滑函数列fs，这种方法称为函数的光滑化或正则化。
卷积的概念还可以推广到数列、测度以及广义函数上去。


卷积是两个变量在某范围内相乘后求和的结果。如果卷积的变量是序列x(n)和h(n)，则卷积的结果
，
其中星号*表示卷积。当时序n=0时，序列h(-i)是h(i)的时序i取反的结果；时序取反使得h(i)以纵轴为中心翻转180度，所以这种相乘后求和的计算法称为卷积和，简称卷积。另外，n是使h(-i)位移的量，不同的n对应不同的卷积结果。
如果卷积的变量是函数x(t)和h(t)，则卷积的计算变为
，
其中p是积分变量，积分也是求和，t是使函数h(-p)位移的量，星号*表示卷积。


差分，又名差分函数或差分运算，是数学中的一个概念。它将原函数  映射到 。差分运算，相应于微分运算，是微积分中重要的一个概念。
微积分学
函数 · 导数 · 微分 · 积分显示▼基础概念显示▼一元微分显示▼一元积分显示▼多元微积分显示▼微分方程显示▼数学家

	* 查
	* 论
	* 编

目录

	* 1 差分的定义
	* 
		* 1.1 前向差分
		* 1.2 逆向差分

	* 2 差分的阶
	* 3 差分的性质
	* 4 牛顿数列
	* 5 参见
	* 6 参考文献

差分的定义差分的定义分为前向差分和逆向差分两种。
前向差分函数的前向差分通常简称为函数的差分。对于函数，如果：
，则称为的一阶前向差分。在微积分学中的有限差分（finite differences），前向差分通常是微分在离散的函数中的等效运算。差分方程的解法也与微分方程的解法相似。当是多项式时，前向差分为Delta算子，一种线性算子。前向差分会将多项式阶数降低1。
逆向差分对于函数，如果：
则称为的一阶逆向差分。
差分的阶称为的阶差分，即前向阶差分 ，如果
根据数学归纳法，有
其中，为二项式系数。
特别的，有
前向差分有时候也称作数列的二项式变换
差分的性质对比解析函数中的微分的属性，差分的性质有：

	* 如果C为常数，则有


	* 线性：如果 和 为常数，则有


	* 乘法定则：


	* 除法定则：

或
	* 级数：

牛顿数列牛顿数列（级数），也称作牛顿前向差分方程是一个以数学与物理学家牛顿命名的函数关系。具体为：
要注意的是，上式对所有的多项式都成立，但只对部分解析函数成立。其中
为二项式系数，
为  的  阶下降阶乘幂。牛顿数列与泰勒级数的相似性是哑微积分的一个典型。
卡尔森定理（Carlson's theorem）指出，如果一个函数的牛顿数列存在，则该函数存在的牛顿数列是唯一的。然而牛顿数列并不总存在。
牛顿数列是差分多项式（差分级数）的特例。


在数学中，海森矩阵（Hessian matrix 或 Hessian）是一个自变量为向量的实值函数的二阶偏导数组成的方块矩阵，此函数如下：

如果 f 所有的二阶导数都存在，那么 f 的海森矩阵即：

H(f)ij(x) = DiDjf(x)

其中 ，即
可见，多元函数的二阶导数就是一个海森矩阵
 海森矩阵被应用于牛顿法解决的大规模优化问题。
 
混合偏导数和海森矩阵的对称性

海森矩阵的混合偏导数是海森矩阵非主对角线上的元素。假如他们是连续的，那么求导顺序没有区别，即
上式也可写为
在正式写法中，如果 f 函数在区域 D 内连续并处处存在二阶导数，那么 f的海森矩阵在 D 区域内为对称矩阵。




给定二阶导数连续的函数，海森矩阵的行列式，可用于分辨 f 的临界点是属于鞍点还是极值点。

对于 f 的临界点 (x0,y0) 一点，有 ，然而凭一阶导数不能判断它是鞍点、局部极大点还是局部极小点。海森矩阵可能解答这个问题。

    H > 0 ：若，则(x0,y0)是局部极小点；若，则(x0,y0)是局部极大点。
    H < 0 ：(x0,y0)是鞍点。
    H = 0 ：二阶导数无法判断该临界点的性质，得从更高阶的导数以泰勒公式考虑。

	雅可比矩阵
雅可比矩阵的重要性在于它体现了一个可微方程与给出点的最优线性逼近。因此，雅可比矩阵类似于多元函数的导数。
假设F:Rn→Rm 是一个从欧式n维空间转换到欧式m维空间的函数。这个函数由m个实函数组成: y1(x1,...,xn), ..., ym(x1,...,xn). 这些函数的偏导数(如果存在)可以组成一个m行n列的矩阵，这就是所谓的雅可比矩阵：
 
此矩阵表示为：
 ，或者  
这个矩阵的第i行是由梯度函数的转置yi(i=1,...,m)表示的
如果p是Rn中的一点，F在p点可微分，那么在这一点的导数由JF(p)给出(这是求该点导数最简便的方法)。在此情况下，由F(p)描述的线性算子即接近点p的F的最优线性逼近，x逼近与p
}- 
编辑] 例子
由球坐标系到直角坐标系的转化由F函数给出:R × [0,π] × [0,2π] → R3
 
此坐标变换的雅可比矩阵是
 
R4的f函数:
 
其雅可比矩阵为:
 
此例子说明雅可比矩阵不一定为方矩阵。
编辑] 在动态系统中
考虑形为x' = F(x)的动态系统，F : Rn → Rn。如果F(x0) = 0，那么x0是一个驻点。系统接近驻点时的表现通常可以从JF(x0)的特征值来决定。
编辑] 雅可比行列式
如果m = n，那么F是从n维空间到n维空间的函数，且它的雅可比矩阵是一个方块矩阵。于是我们可以取它的行列式，称为雅可比行列式。
在某个给定点的雅可比行列式提供了F在接近该点时的表现的重要信息。例如，如果连续可微函数F在p点的雅可比行列式不是零，那么它在该点具有反函数。这称为反函数定理。更进一步，如果p点的雅可比行列式是正数，则F在p点的取向不变；如果是负数，则F的取向相反。而从雅可比行列式的绝对值，就可以知道函数F在p点的缩放因子；这就是为什么它出现在换元积分法中。
例子
设有函数F : R3 → R3，其分量为：
 
则它的雅可比行列式为：
 
从中我们可以看到，当x1和x2同号时，F的取向相反；该函数处处具有反函数，除了在x1 = 0和x2 = 0时以外。


凸函数是一个定义在某个向量空间的凸子集C（区间）上的实值函数f，而且对于凸子集C中任意两个向量x1,x2,f((x1+x2)/2)≤（f(x1)+f(x2))/2。 
凸函数的二次导数必须是正数。
 

仿射函数即由1阶多项式构成的函数，一般形式为 f (x) = A x + b，这里，A 是一个 m×k 矩阵，x 是一个 k 向量,b是一个m向量，实际上反映了一种从 k 维到 m 维的空间映射关系。
设f是一个矢性（值）函数，若它可以表示为f(x1,x2,…,xn)=A1x1+A2x2+…+Anxn+b，其中Ai可以是标量，也可以是矩阵，则称f是仿射函数。
其中的特例是，标性（值）函数f(x)=ax+b，其中a、x、b都是标量。此时严格讲，只有b=0时，仿射函数才可以叫“线性函数”（“正比例”关系）。
就一般情形，函数f是仿射函数的充要条件是：对于任意两组向量x1,x2,…,xn与y1,y2,…,yn，对于任 意0<=p<=1，如果f[px1+(1-p)y1,px2+(1-p)y2,…,pxn+(1- p)yn]==pf(x1,x2,…,xn)+(1-p)f(y1,y2,…,yn)。（“==”表示恒等）
一般称线性组合“p1x1+p2x2+…+pnxn，其中p1+p2+…+pn=1”为仿射组合；一般称所有pi>=0的仿射组合为凸组合。
其实一般意义上的仿射函数是一个矩阵函数,如果构成一个类似LMI的不等式,可以成为仿射矩阵不等式.

仿射函数即由由1阶多项式构成的函数，一般形式为 f (x) = A x + b，这里，A 是一个 m×k 矩阵，x 是一个 k 向量,b是一个m向量，实际上反映了一种从 k 维到 m 维的空间映射关系。
设f是一个矢性（值）函数，若它可以表示为f(x1,x2,…,xn)=A1x1+A2x2+…+Anxn+b，其中Ai可以是标量，也可以是矩阵，则称f是仿射函数。
其中的特例是，标性（值）函数f(x)=ax+b，其中a、x、b都是标量。此时严格讲，只有b=0时，仿射函数才可以叫“线性函数”（“正比例”关系）。
 













From Stanford material。

Convex Optimization Overview Part I

convex set。rx+(1-r)y  belongs to C. 
就是说如果二个点属于c，那么这二个点形成的线上的点也都属于这个set。那么这个set就是凸的。
convex的差集也是convex的。


convex function:
对二边对theta求导数，可以得到下面的公式，也就是梯度下降的公式。


Jensen inequality



matrix trace, 

 
设有N阶矩阵A，那么矩阵A的迹（用tr（A）表示）就等于A的特征值的总和，也即A矩阵的主对角线元素的总和。
1.迹是所有对角元的和
2.迹是所有特征值的和

characteristic value 特征值
 设 A 是n阶方阵，如果存在数m和非零n维列向量 x，使得 Ax=mx 成立，
则称 m 是A的一个特征值（characteristic value)或本征值（eigenvalue) 

characteristic vector




	
	贝叶斯方法有着非常广泛的应用，但是初学者容易被里面的概率公式的给吓到，以至于望而却步。所以有大师专门写个tutorial，命名为 “bayesian inference with tears”。 我本人也深受其苦，多次尝试学习而不得其门而入。终于有一天，一种醍醐灌顶的感觉在脑海中出现，思路一下子清晰了，原来bayes估计竟然是这么一回事。 本blog只是为了让还处在痛苦的学习过程中的人能够快速把握概念，理清思路，高手请绕道而行 :)

贝叶斯估计要解决的是概率估计问题， 也就是说，已知一些样本，他们满足某种分布，需要估计这种分布的参数或者新数据出现的概率。说到概率估计，就不能不先说说最大似然方法。最大似然是一种最 基本的参数估计方法，相信学过概率的人都应该知道。最大似然就是寻找最可能的参数，使得这些采样样本出现的概率最大。举个简单的例子吧。假设一个盒子的高 度h满足正态分布N(h,1), 三次测量结果分别为 X={11，10.5，11.5} cm, 根据最大似然方法:

P(X|h)=∏i=1Np(xi|h)=∏i=1N12πexp{?(xi?h)2σ2}
这里，
h=argmaxhP(X|h)=argmaxhlog P(X|h) =argmaxhexp{∑i=1N(xi?h)2}

通过简单计算，可以得到h = 11cm，对新的测量的数据的可能出现概率，则由 N(11,1)给出。
最大似然估计是在对被估计量没有任何先验知识的前提下求得的。如果已知被估计参数满足某种分布，则需要用到最大后验估计。比如，在前面提到的例子中，假设h服从正态分布N(10.5,1)，要估计h的值，根据贝叶斯理论
P(h|X)=P(X|h)P(h)P(X)

这里P(X) 和我们要估计的参数无关，所以
h=argmaxhP(X|h)=argmaxhP(X|h)P(h) =argmaxhexp∑i=1N(xi?h)2+(h?10.5)2

通过简单计算，可以得到 h= 10.875cm。根据MAP的结果，对新的测量的数据的可能出现概率，则由 N(10.875,1)给出。

贝叶斯估计其实要解决的不是如何去估计参数，而是如何估计新的测量数据的出现的概率的，但其过程并不需要要计算参数h，而是通过对h的积分得出：
P(x|h)=∫h～N(10.5,1)p(h|X)p(x|h)dh

这 个有点想求函数的数学期望。在实际应用中，为了便于计算，一般根据似然函数，对先验概率进行假设，从而使得先验分布和后验概率有相同的表达形式，这就涉及 到共轭先验的概念。如果先验概率和似然函数的关系能够使得先验和后验概率有相同的函数形式，则可认为先验概率是似然函数的共轭先验。共轭先验在贝叶斯推理 中有非常广泛的应用，很多问题都是通过共轭先验求解的。 








