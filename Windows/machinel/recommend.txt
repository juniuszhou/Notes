衡量用户相似度，可以使用欧式距离
这个系统做的事情是对每二个用户计算他们的相似度，计算是根据他们在对过去共同看过的
电影的评价是否相似。
然后对于推荐系统来说，找到某个用户没有看过的电影，根据其它用户的评价 times 相似度
得到这个用户对电影最有可能的评价，评价越高就越值得推荐。

相似度的测量可以选取不同的距离公式，欧式，曼哈顿，等等。

如果把这个关系倒过来，我们就有了另外一种推荐系统，我们有商品和用户。
假设有个新用户没有买任何商品，我们任何推荐。我们可以把关系倒过来，假设商品之间
的关联性。这里说关联性是因为很多人买了啤酒又买尿布。
但是如果我们把商品限制在一个类别就可以计算相似度了。 比如买了c++ and java.

这样当我们买了一个商品后，系统可以推荐其它相似的商品。

user-based and item-based filtering.

基于用户的协同过滤——基于人口统计学的推荐 区别
　　基于用户的协同过滤推荐机制和基于人口统计学的推荐机制都是计算用户的相似度，并基于“邻居”用户群计算推荐，但它 们所不同的是如何计算用户的相似度，基 于人口统计学的机制只考虑用户本身的特征，而基于用户的协同过滤机制可是在用户的历史偏好的数据上计算用户的相似度，它的基本假设是，喜欢类似物品的用户 可能有相同或者相似的口味和偏好。
　　基于物品的协同过滤——基于内容的推荐 区别
　　基于项目的协同过滤推荐和基于内容的推荐其实都是基于物品相似度预测推荐，只是相似度计算的方法不一样，前者是从用户历史的偏好推断，而后者是基于物品本身的属性特征信息。

既然要谈的是推荐“技术”，那么我得先把推荐问题用数学语言形式化了。淡定淡定，推荐问题形式化后非常简单干净——就三个矩阵（从这里往下得有一丢丢想像力，能在脑海里想象简单的矩阵操作）。最重要的一个矩阵是评分或偏好矩阵（Rating/Preference Matrix），其每一行对应一个用户，每一列对应一件物品，矩阵中的任一元素就是某用户对某物品的感兴趣程度（评分可以用正整数表示，点赞神马的可以用0/1表 示），不失一般性，下面我们仅基于评分矩阵讨论。这个评分矩阵是极其稀疏的，因为每个用户只可能对很少一部分物品打分。第二个矩阵是用户信息矩阵，每一行 对应一个用户，每一列对应一个用户属性（如年龄、职业、地区、标签等）。第三个矩阵是物品信息矩阵，每一行对应一件物品，每一列对应一个物品属性（如电影 的流派、导演、演员等）。推荐问题的目标就是：基于给定的三个矩阵，把评分矩阵中缺失元素的评分预测出来，并基于预测出来的评分把得分高的物品推荐给相应 用户。这里值得注意的是，只有评分矩阵是所有推荐技术所必需的，用户信息矩阵与物品信息矩阵这两者是可选的。
真实推荐系统面临最大的挑战是评分矩阵的大规模与稀疏性。

接下来我把一些当前常用的推荐技术分门别类。推荐技术可先分为三大类：基于人口统计的推荐技术（Demography-based）、基于物品内容的推荐技术（Content-based）、以及基于协同过滤的推荐技术（Collaborative Filtering，简称CF）。基于人口的又包括基于用户资料的（User Profile）和基于信任关系的（社交网络上的好友关系）等。基于物品内容的又可细分为基于元数据的（即Metadata，比如电影的流派、导演、演员等）和基于内容数据的（比如视频数据、音频数据）等——真实应用大多是基于元数据的，基于内容数据的推荐系统由于语义鸿沟（Semantic Gap）和效率问题，做了几十年，一直未突破（深度学习能突破么，拭目以待呵呵）。

虽然基于人口和基于内容的两大类推荐技术在实际中的应用极广而且效果在某些应用场景下不比第三类技术协同过滤差，那为什么协同过滤技术一跃成为当今主流的推荐技术了呢？有以下几方面原因：1）协同过滤问题相当干净，只需要一个评分矩阵，不需要用户信息与物品信息，这解决了用户物品信息缺失场景下的推荐问题。2）协同过滤问题的本质是矩阵补全问题（Matrix Completion），也就是把一个稀疏矩阵的缺失元素给估计出来，这是机器学习中一个经典问题，除了推荐之外还有无数的应用都可归结为矩阵补全问题，所以机器学习的高速发展也促进了协同过滤技术。协同过滤技术可以继续分为基于记忆的（Memory-based）和基于模型的（Model-based）。基于记忆的继续可分为基于用户的（User-based）和基于物品的（Item-based）；而基于模型的可以继续分为基于矩阵分解的（Matrix Factorization）和基于联合聚类的（Co-clustering）。基于记忆的协同过滤技术使用的是K-近邻（K-Nearest Neighbors）的思想，而基于模型的协同过滤技术使用的是机器学习方法。
真实系统都是使用的混合策略（Hybrid Strategy）， 多为基于人口、基于元数据、以及基于用户或物品的协同过滤推荐技术的各种组合。有些混合策略 是对不同推荐技术的结果加权相加（Weighting）；有些是根据场景不同在不同技术间跳转（Switching），比如新用户基于人口统计老用户基于协同过滤；有些是一个网页上不同区域同时显示不同推荐技术的结果（Mixing）；有些是用一个推荐技术对另一个推荐技术输出的结果进行提升（Cascading）。



首先是基于人口统计学的，该类推荐技术需要基于用户信息矩阵和评分矩阵。原理很简单，就是查找用户信息矩阵中背景类似的用户，然后把对应评 分矩阵中打高分的物品推荐给背景类似的用户。举个例子，用户信息上显示两个人年龄相仿居于湾区互联网从业者，于是系统就会认为这两人相关性强会有共同爱 好，把其中一人打高分的电影推荐给另一个。这种推荐技术的优点是简单，一些相关性查询操作就能搞定，而且没有“冷启动（Cold-start）”问题（即用户缺失历史评分纪录）；缺点是无法个性化推荐，基于人口统计相似度的假设太强，比如同为IT男，一个技术宅，一个伪文青，你把技术宅喜欢的东西推荐给伪文青肯定是不靠谱的，比如我排斥一切XX侠 的电影。

接下来是基于物品内容的推荐技术，该类推荐技术需要基于物品信息矩阵和评分矩阵（这里只讨论基于元数据的，基于真实内容的开门课都讲不完）。该类 推荐技术的原理也很简单，基于元数据计算物品之间的相关性，然后把与该用户以前打高分的物品最相关的物品推荐给他。这类推荐技术比前一种靠谱，因为用户在 同类物品上一般会表现出相同的兴趣程度。举个例子，我如果对《巴黎我爱你》打了个高分，那么推荐系统就会向我推荐强关联的《纽约我爱你》，而我也会对同一 血统的电影很感兴趣。因此，该类技术的优点就是对偏好的建模较为精细与准确；缺点是依赖于物品元数据包含的信息量，以及存在冷启动问题（需要用户的历史评 分）。

接下来介绍基于记忆的协同过滤技术，该类推荐技术的标准问题设置仅需要评分矩阵，当然近年来学术界有些关于迁移学习（Transfer Learning）在推荐系统中的研究会使用到用户与物品的信息矩阵、甚至使用另一个域的评分矩阵（我以前在推荐系统中的工作主要在这块，感兴趣的同学可以用谷歌百度下一个二页纸的小文“Cross-Domain Collaborative Filtering: A Brief Survey”）， 但这里我们只讨论标准的协同过滤问题设置。

注意下面这个用户相似度是根据他们是否共同对一个item有相似的评价，来度量
这二个用户的相似性。
基于用户的协同过滤分为两步：第一步是计算用户之间的相关度，这里的相关度是评分矩阵行向量间的相关度，其直观 意义就是如果两个用户在相同物品上打的分越接近，那么这两个用户的偏好也越接近。如果评分矩阵是一个没有缺失项的满矩阵，那么行向量之间的相似度直接可以 用欧式距离或者夹角余弦计算；由于评分矩阵是稀疏矩阵，因此计算相关性首先要把两个行向量之间的交集（打过分的物品）找出来，并只在该交集上计算一个类似 夹角余弦的值，叫作皮尔森相关系数（Pearson Correlation Coefficients）。在取得了与所有用户两两之间的相关性后，第二步就是预测该用户的缺失评分。给定一个待预测用户，找到他的K-近邻用户集合，他的缺失评分就是用其K-近邻用户对应物品上的历史评分用相关性加权平均得到。基于物品的协同过滤和基于用户的是对称的，一个是对行操作，一个是对列操作，方法和原理都是一样的。
从这里往后的内容主要将介绍基于模型的协同过滤技术 SVD。在大多数推荐系统的介绍中一般直接就把基于模型与矩阵分解等同起来了，因为应用到实际推荐系统中的基于模型的推荐技术一般都是基于矩阵分解的，比如Netflix百万大奖得主提出的(Time)SVD++方法。又跑题了，继续说基于模型的推荐技术。除了矩阵分解，这里我还 要额外介绍一种基于联合聚类的技术，所谓联合聚类，就是对用户与物品（即评分矩阵的行与列）同时聚类，聚类的方法可以是简单的K-Means，但更优美的建模方法是双向混合模型——我个人非常喜欢这种建模方式，虽然对于评分预测的性能没有基于矩阵分解的好（因为矩阵分解的目标就是拟合评分而混合模型的目标是估计用户与物品在潜在类型上的分布）。


先说基于矩阵分解的方法吧。给定一个评分矩阵（大小为N*M），把该矩阵分解为两个矩阵的乘积，一个是用户特征矩阵（大小为N*K），一个是物品特征矩阵（大小为M*K），其中潜在特征（latent features）的维度远小于用户数与物品数；目标函数就是两个特征矩阵的重构与给定评分矩阵在那些可见评分上的值尽可能接近，一般使用矩阵范数（Frobenius norm），即两个矩阵相减所有元素上残差平方和；再加上对两个特征矩阵的矩阵范数作为正则化项。改优化问题常用两种方法解决：一种是交替最小二乘（Alternative Least Squares），交替优化用户特征矩阵与物品特征矩阵，在优化其一的时候固定另一个的值视其为已知，这样就相当于每轮解决一个标准的最小二乘问题，最后收敛到局部最优解。该方法的优点是收敛速度快，缺点是需要对用户数与物品数大小的方正求逆，难以规模化。

另一种是随机梯度下降（Stochastic Gradient Descent）， 对每个用户与每个物品（评分矩阵的行与列）分别求偏导建立牛顿迭代公式，然后用可见评分顺序对这些迭代公式进行更新。该方法的优点是可以并行化、效率高， 目前大规模矩阵分解都是用的这种优化算法；缺点可能是收敛速度没有第一种快（这点我不是很确定）。最后说说这种形式矩阵分解的物理含义。这样分解成两部分 后，就相当于用户和物品都被放置到一个潜在的K维特征空间，只要拥有相似潜在特征的用户与物品，他们的夹角就小乘积就大得到的预测评分也就相应更高。那么凭什么我们能指定一个“潜在的K维特征空间”呢？拿Pandora的音乐推荐举例子，每个音乐有几百条“音乐基因”就是音乐的显式特征（不知道音乐基因的可以去古歌百度一下Music Gene Project）。如果不降维的话，那么音乐特征矩阵和用户特征矩阵的纬度就是其真实的特征纬度。假设我们基于主成分分析（PCA）用相同的一套基分别对这两个矩阵进行线性变换，那么得到的两个矩阵就可以认为是投影到潜在特征空间的两个矩阵，而这两个矩阵的乘积和原来的两个矩阵是一样的（因为当中两个投影矩阵的乘积是单位矩阵）。那么假如我们只用前K个基投影呢？那我们就得到了只有K维潜在特征空间的低秩矩阵。所以在实际问题中，我们都不需要知道真实的特征空间，只需要人为指定一个K维潜在特征空间就可以了，得出的结果可以认为是真实特征经过某个线性变化后投影到一个低维潜在特征空间。


最后介绍基于联合聚类的方法。这类方法的物理意义更直观，其实也能表示成为矩阵分解的形式，但不同的是联合聚类把评分矩阵（大小为N*M）分解为三部分，一个是用户隶属度矩阵（N*K），表示每个用户在K个潜在用户组上的分布情况，所有元素为正每行加起来为1；一个是物品隶属度矩阵（M*L），表示每个物品在L个潜在物品组上的分布情况，所有元素为正每行加起来为1；还有一个是压缩评分矩阵（K*L），表示某个用户组对某个物品组给的评分。
使用这三个矩阵的乘积重构评分矩阵可以对缺失评分进行预测。解决该问题最简单的方法是分别对行与列进行K-Means聚类，然后用户与物品隶属度矩阵就根据聚类结果把对应的组设为1其它为0（硬聚类），而压缩评分矩阵是每个联合聚类中评分的平均值。更一般性的建模方法是令两个隶属度矩阵为在潜在组别上的分布（软聚类），这需要使用期望最大（Expectation-Maximization）算法解决；进一步地考虑贝叶斯，由于隶属度就是Dirichlet分布，那么其实该联合聚类问题可以使用Latent Dirichlet Allocation的变种建模，叫作Bi-LDA，使用吉布斯采样解决。这类方法的具体细节就不介绍了。


至此为止，基本的推荐技术大体都过了一遍了。当前最重要的问题还是大规模矩阵分解问题（我也无法免俗大数据啊）
其实我本来还想谈一下在线推荐系统，也是如今精准广告投放背后的核心技术，但是也因为问题 的设置和协同过滤有很大的不同，技术上也几乎没有什么交集，就不展开了。在线推荐系统的主要技术是一大类被称为Multi-Armed Bandits（MAB）的方法——没错就是老虎机！广告投放就像赌博，你选哪个广告投放出去都会有不同的回报，随着一次又一次的尝试，从失败中吸取教训，慢慢学习到背后隐含的规律，之后就可以保持大概率的赢面。MAB的在线学习策略遵循的是“开采（Exploitation）”与“探索（Exploration）”，一边尽量投注之前赢面较大的广告，一 边又不停尝试其它未知底细的广告以发现更高的赢面。





