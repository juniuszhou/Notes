HypothesisTest.txt

假设检验(Hypothesis Testing)是数理统计学中根据一定假设条件由样本推断总体的一种方法。具体作法是：根据问题的需要对所研究的总体作某种假设，记作H0；选取合适的统计量，这个统计量的选取要使得在假设H0成立时，其分布为已知；由实测的样本，计算出统计量的值，并根据预先给定的显著性水平进行检验，作出拒绝或接受假设H0的判断。

假设检验的基本思想是小概率反证法思想。小概率思想是指小概率事件（P<0.01或P<0.05）在一次试验中基本上不会发生。反证法思想是先提出假设(检验假设H0)，再用适当的统计方法确定假设成立的可能性大小，如可能性小，则认为假设不成立，若可能性大，则还不能认为不假设成立。


设A是关于总体分布的一项命题，所有使命题A成立的总体分布构成一个集合h0，称为原假设(常简称假设)。使命题A不成立的所有总体分布构成另一个集合h1，称为备择假设。如果h0可以通过有限个实参数来描述，则称为参数假设，否则称为非参数假设(见非参数统计)。如果h0(或h1)只包含一个分布，则称原假设(或备择假设)为简单假设，否则为复合假设。

第一类错误是真实情况为h0成立(即θ∈嘷0)，但判断h0不成立，犯了“以真为假”的错误。
第二类错误是h0实际不成立(即θ∈嘷1)，但判断它成立，犯了“以假为真”的错误


# concept 
1. likelihood ratio. this parameter to control the probability of type one and type two error.
likelihood ratio = P(H0 | X) / P(H1 | X) 

L1/L0就是似然比

我们认为：
比值越大，拒绝H0的概率越高

2. null hypothesis, alternative hypothesis.

3. significance level and power.
significance level is the possibility of make type one error.
power is the possibility of avoid type two error.

显著性水平 is alpha.
置信水平和显著性水平之和为1.

势函数是样本落入假设检验的拒绝域的概率

4. 
simple hypothesis. the null hypothesis and alternative hypothesis already point out
the distribution.
composite hypothesis, null and alternative hypothesis don't the point out distribution.

p-value. 
而p值的大小，在统计学中就是备择假设是对的，数据却支持原假设的可能性。
而p值，是在原假设正确的前提下，出现观察结果或比之更极端情形的概率，其计算根本不涉及备择假设。

甚至有了“α犯第一类错误时所能容许的最大概率，p值是实际观察时犯第一类错误的概率”等等说法。


p的含义是在零假设H0成立的条件下，得到比实际测量所得的数据更加极端的数据（D）的概率，也就是p（D | H0）。上面加粗的这句话决不可漏掉，p值是在零假设成立的前提假设下的条件概率，不是在得到实验数据后零假设成立的概率p（H0 | D）。p值是条件概率这一点经常被人忽略，从而导致很多对统计的误用和误解，即使是专业的研究者（也就是上课教我们统计的那些老师）也有很多没有意识到p的本质，国内外皆然（有研究者做过调查，不是我随口瞎说的）。当p达到一定的阈限的时候，比如常见的p < 0.05，我们就会说实验结果是显著的。这就是统计上的显著性。


如果想弄清楚p和α(significance level)的关系，就不得不提到R.A.Fisher派和J.Neyman-E.Pearson派之间的争论。细心观察就会发现，α是建立在H0和H1的体系之下的，即α为犯第一类错误（“弃真”）的概率，这就需要事先给定原假设H0与备择假设H1。而p值，是在原假设正确的前提下，出现观察结果或比之更极端情形的概率，其计算根本不涉及备择假设。事实上，Fisher非常反感备择假设。这里涉及科学推断的方法论之争，我也不是很懂，就不多说了。Fisher在计算出p值以后，根据其大小判断是否拒绝原假设。他认为，p值的门限可以取0.05或0.01等等比较小的数。他把这个门限称为significance level，即显著性水平（注意，绝不是α。Fisher在提出显著水平时，还没有α的概念）。至于为什么计算p值时，也要把“更极端”的情形考虑进来，大象的理解和Fisher当初的设计是一致的，即考虑连续型概率分布函数（pdf），任何一个特定观察值出现的概率其实都是0，因此把极端情形加进来，更为得当。另一方面，作为Neyman-Pearson派，他们在H0-H1的体系下，通过事先给定α，即犯第一类错误的概率来划定拒绝域的边界。应该注意到的是，所谓拒绝域，是某个具体的统计量或类似参数的拒绝域，是通过预先给定的α及累积分布函数推出来的。所以在该体系下，做假设检验时，大家比较的就是观察值和拒绝域边界值的位置关系，如果观察值落在拒绝域之内，则接受H1；反之接受H0。因此，Neyman-Pearson派不会刻意关注p的具体值，他们也不去计算p值，而是只看观察结果是否落在拒绝域之内，就可以了。所以，严格遵循这一体系的学者或教材，几乎不会提到p值，更不会用p和α去比大小，从而判断是否拒绝H0。这一点，可以参见葛余博编的《概率论与数理统计》等书。很有趣的是，Neyman-Pearson他们把α也称作显著性水平，甚至也把0.05作为常用的α值。这极容易让人将它与Fisher在早些年提出的显著性水平视作等同。于是，Fisher大为光火，称Neyman把概念混淆了。然而，由于各种各样的原因（如讲授数理统计课程的人为了将两派意见统一），p和α还是被不加说明地融合在一起了，甚至有了“α犯第一类错误时所能容许的最大概率，p值是实际观察时犯第一类错误的概率”等等说法。所以，很多很多的学者和教材，都会用p和α去比大小，从而判断是否接受H0。实际上，无论是Fisher还是Neyman，当他们看到上述的说法时，都会不爽的，因为这种和稀泥的方法，都背离了他们各自的初衷:-)2014.7修正之所以把“更极端”情形考虑进来，更合理的解释为：既然要考察当前观察到的事件有多么极端，那就不仅要知道该事件本身发生的概率，还要知道它在整个事件空间中所处的“位置”，即这个事件与其他各种事件相比，其极端性如何。因而，只有再知道还有哪些事件比之更为极端，以及这些事件可能发生的总概率，才能全面判断该事件本身的极端程度。类比生活中的例子，要想衡量一个学生的成绩好坏，不仅要看他自己考了多少分，以及全年级还有多少人也考到相同分数，还需要看有多少人比他考得好。具体来说，假如某学生考了80分，而全年级500人中还有1人也考了80分，那么P(分数=80) = 2/500 = 0.004。单看这一概率的确很小，但此时我们并不能断言他的成绩是好还是坏，因为有可能还有数百人都考到80分以上，当然也有可能考到80分已能名列前茅——这就需要看他成绩的排名如何。反观p值，它恰恰就能衡量这种“排名”。假如我们知道80分及80分以上的人共有300人，那么不严谨地说，考到80分这件事的“p值”就是300/500 = 0.6，该学生的成绩并不突出。用概率论的语言来说，p值反映的是累积分布函数（cdf）的取值，而非概率密度函数（pdf）的取值。



5 how to measure if a hypothesis is the best.
for simple hypothesis, the likelihood ratio is the best.


6. power is the probability of reject the null hypothesis when it is false.

